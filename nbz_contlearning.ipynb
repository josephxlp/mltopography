{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tasks:\n",
    "- train \n",
    "- predict \n",
    "- qgis check rasters \n",
    "- package to send to Rolf, @@"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (collect_tiff_paths,split_data_two,load_many_patch_to_df,\n",
    "                   get_row_paths_and_names,load_patch_to_df)\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import time \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rparams = {'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',#['rmse','mae','mse'],\n",
    "        #'learning_rate': 0.8935583206145743,\n",
    "        'num_leaves': 2080,\n",
    "        'max_depth': 16,\n",
    "        'min_data_in_leaf': 600,\n",
    "        'lambda_l1': 45,\n",
    "        'lambda_l2': 35,\n",
    "        'min_gain_to_split': 10,\n",
    "        'bagging_fraction': 0.9,\n",
    "        'bagging_freq': 10,\n",
    "        'feature_fraction': 1.0,\n",
    "        'verbose': 0,\n",
    "        'n_estimators': 500,\n",
    "        'seed':123,\n",
    "        'early_stopping_rounds':20,\n",
    "        'first_metric_only':True\n",
    "    }\n",
    "\n",
    "\n",
    "# If you are dealing with multi-class classification, you might use:\n",
    "# cparams['objective'] = 'multiclass'\n",
    "# cparams['metric'] = 'multi_logloss'\n",
    "# cparams['num_class'] = <number_of_classes>  # Specify the number of \n",
    "\n",
    "\n",
    "cparams = rparams.copy()\n",
    "\n",
    "# Modify parameters for classification\n",
    "cparams['objective'] = 'binary'  # Use 'binary' for binary classification\n",
    "cparams['metric'] = 'binary_logloss'  # Common metric for binary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1521, 6)\n",
      "(136, 6) (16, 6)\n"
     ]
    }
   ],
   "source": [
    "roi = 'tsap'\n",
    "nboost = 10000\n",
    "sa = 0.1 #1\n",
    "st = 0.1\n",
    "path = \"/media/ljp238/12TBWolf/ARCHIEVE/ZOUT/datasets_TILES12_patches256/\"\n",
    "dpath = \"/media/ljp238/12TBWolf/ARCHIEVE/ZOUT/datasets_TILES12_patches256/N13E103\"\n",
    "dfpath = collect_tiff_paths(dpath)\n",
    "acols = ['cdem_dem', 'cdem_wbm', 'edem_dem', 'edem_demw84', 'egm08', 'egm96',\n",
    "       'esawc', 'ldem_label', 'ldtm', 'pdem', 'pdem_label', 'tdem_dem_clean',\n",
    "       'tdem_dem_clean_binmask', 'tdem_dem_filled', 'tdem_dem_hsd',\n",
    "       'tdem_dem_rgx', 'tdem_dem_slp', 'tdem_dem_tpi', 'tdem_dem_tri',\n",
    "       'tdem_hem']\n",
    "\n",
    "fcolYc = 'ldem_label'\n",
    "fcolYr = 'ldtm'\n",
    "fcolX =  ['egm08', 'egm96','tdem_hem','tdem_dem_filled'] \n",
    "FTCOLSC =  fcolX + [fcolYc , fcolYr]\n",
    "pathdf = dfpath[FTCOLSC]\n",
    "print(pathdf.shape) # filter out pad ones for the img \n",
    "\n",
    "train_paths, valid_paths =  split_data_two(pathdf.sample(frac=sa),test_pct= st)\n",
    "print(train_paths.shape, valid_paths.shape)#, test_paths.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_df = load_many_patch_to_df(valid_paths[FTCOLSC])\n",
    "X_vali = val_data_df.drop(fcolYr, axis=1)\n",
    "y_vali = val_data_df[fcolYr]\n",
    "val_data = lgb.Dataset(X_vali, label=y_vali, free_raw_data=False)\n",
    "\n",
    "# test_data_df = load_many_patch_to_df(test_paths[FTCOLSC])\n",
    "# X_test = val_data_df.drop(fcolYr, axis=1)\n",
    "# y_test = val_data_df[fcolYr]\n",
    "# test_data = lgb.Dataset(X_test, label=y_test, free_raw_data=False)\n",
    "\n",
    "ti = time.perf_counter()\n",
    "# List to store accuracy scores\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Best model and best validation score\n",
    "best_model = None\n",
    "best_val_score = float('inf')\n",
    "\n",
    "\n",
    "# Training with batches\n",
    "for i in range(len(train_paths)):\n",
    "    #if i > 100: break\n",
    "    print(f'[INFO]:: {i}/ {len(train_paths)}')\n",
    "    paths, names = get_row_paths_and_names(train_paths[FTCOLSC], i)\n",
    "    try:\n",
    "        di = load_patch_to_df(paths, names)\n",
    "        X_train = di.drop(fcolYr, axis=1)\n",
    "        y_train = di[fcolYr]\n",
    "        train_data = lgb.Dataset(X_train, label=y_train, free_raw_data=False)\n",
    "\n",
    "        # If first batch, train initial model, else update model\n",
    "        if i == 0:\n",
    "            model = lgb.train(rparams, train_data, valid_sets=[train_data, val_data], \n",
    "                              num_boost_round=nboost, callbacks=[lgb.early_stopping(100)])\n",
    "        else:\n",
    "            model = lgb.train(rparams, train_data, valid_sets=[train_data, val_data], \n",
    "                              init_model=model, num_boost_round=nboost, callbacks=[lgb.early_stopping(100)])\n",
    "\n",
    "        # Calculate accuracy for the current batch\n",
    "        y_train_pred = model.predict(X_train) #> 0.5).astype(int)\n",
    "        y_val_pred = model.predict(X_vali) #> 0.5).astype(int)\n",
    "        train_accuracy = root_mean_squared_error(y_train, y_train_pred)\n",
    "        val_accuracy = root_mean_squared_error(y_vali, y_val_pred)\n",
    "\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        # Save the best model based on validation accuracy\n",
    "        if val_accuracy < best_val_score:\n",
    "            best_val_score = val_accuracy\n",
    "            best_model = model\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in batch {i}: {e}\")\n",
    "        pass \n",
    "# replace valid by test?\n",
    "# Save the best model\n",
    "best_model.save_model(f'lgbR_{roi}_modeli.txt')\n",
    "\n",
    "# Save accuracy scores to CSV\n",
    "accuracy_df = pd.DataFrame({\n",
    "    'train_RMSE': train_accuracies,\n",
    "    'val_RMSE': val_accuracies\n",
    "})\n",
    "accuracy_df.to_csv(f'lgbR_{roi}_scoresi.csv')\n",
    "\n",
    "# Plot training and validation accuracy over batches\n",
    "plt.plot(train_accuracies, label='Train RMSE')\n",
    "plt.plot(val_accuracies, label='Valid RMSE')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation RMSE Over Batches')\n",
    "plt.savefig('RMSE_plot.png')\n",
    "#plt.show()\n",
    "\n",
    "print('Finished ')\n",
    "\n",
    "tf = time.perf_counter() - ti \n",
    "print(f'run.time={tf/60} min(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pgeoml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
